{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 791 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir =\"data/train\"\n",
    "val_dir =\"data/test\"\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(120, 120),\n",
    "    batch_size=64,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(120, 120),\n",
    "    batch_size=64,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nithi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "models = Sequential()\n",
    "models.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(120, 120, 3)))\n",
    "models.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "models.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "models.add(Dropout(0.25))\n",
    "models.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "models.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "models.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "models.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "models.add(Dropout(0.25))\n",
    "models.add(Flatten())\n",
    "models.add(Dense(1024, activation='relu'))\n",
    "models.add(Dropout(0.5))\n",
    "models.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nithi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.0001, decay=1e-6),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nithi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/28\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5036 - loss: 0.7238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nithi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 513ms/step - accuracy: 0.5101 - loss: 0.7166 - val_accuracy: 0.5300 - val_loss: 0.6866\n",
      "Epoch 2/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 505ms/step - accuracy: 0.5842 - loss: 0.6806 - val_accuracy: 0.5800 - val_loss: 0.6808\n",
      "Epoch 3/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 483ms/step - accuracy: 0.5581 - loss: 0.6770 - val_accuracy: 0.5400 - val_loss: 0.6783\n",
      "Epoch 4/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 491ms/step - accuracy: 0.5735 - loss: 0.6742 - val_accuracy: 0.6000 - val_loss: 0.6611\n",
      "Epoch 5/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 487ms/step - accuracy: 0.6262 - loss: 0.6430 - val_accuracy: 0.5900 - val_loss: 0.6473\n",
      "Epoch 6/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 488ms/step - accuracy: 0.6570 - loss: 0.6217 - val_accuracy: 0.6200 - val_loss: 0.6320\n",
      "Epoch 7/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 487ms/step - accuracy: 0.6480 - loss: 0.6158 - val_accuracy: 0.6100 - val_loss: 0.6218\n",
      "Epoch 8/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 483ms/step - accuracy: 0.6630 - loss: 0.6082 - val_accuracy: 0.6600 - val_loss: 0.6070\n",
      "Epoch 9/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 486ms/step - accuracy: 0.7032 - loss: 0.5614 - val_accuracy: 0.6500 - val_loss: 0.5758\n",
      "Epoch 10/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 492ms/step - accuracy: 0.7075 - loss: 0.5757 - val_accuracy: 0.6400 - val_loss: 0.5883\n",
      "Epoch 11/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 486ms/step - accuracy: 0.7273 - loss: 0.5436 - val_accuracy: 0.7300 - val_loss: 0.5342\n",
      "Epoch 12/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 477ms/step - accuracy: 0.7176 - loss: 0.5367 - val_accuracy: 0.6900 - val_loss: 0.5534\n",
      "Epoch 13/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 469ms/step - accuracy: 0.7348 - loss: 0.5133 - val_accuracy: 0.7400 - val_loss: 0.5225\n",
      "Epoch 14/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 496ms/step - accuracy: 0.7568 - loss: 0.5025 - val_accuracy: 0.7700 - val_loss: 0.5086\n",
      "Epoch 15/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 476ms/step - accuracy: 0.7603 - loss: 0.4687 - val_accuracy: 0.7800 - val_loss: 0.4718\n",
      "Epoch 16/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 464ms/step - accuracy: 0.7965 - loss: 0.4357 - val_accuracy: 0.7600 - val_loss: 0.4605\n",
      "Epoch 17/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 466ms/step - accuracy: 0.8029 - loss: 0.4103 - val_accuracy: 0.7600 - val_loss: 0.4554\n",
      "Epoch 18/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 473ms/step - accuracy: 0.8044 - loss: 0.3967 - val_accuracy: 0.7800 - val_loss: 0.4247\n",
      "Epoch 19/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 461ms/step - accuracy: 0.8221 - loss: 0.3767 - val_accuracy: 0.7200 - val_loss: 0.4667\n",
      "Epoch 20/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 467ms/step - accuracy: 0.8402 - loss: 0.3653 - val_accuracy: 0.7900 - val_loss: 0.4457\n",
      "Epoch 21/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4789s\u001b[0m 654ms/step - accuracy: 0.8421 - loss: 0.3513 - val_accuracy: 0.8200 - val_loss: 0.3753\n",
      "Epoch 22/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 488ms/step - accuracy: 0.8532 - loss: 0.3238 - val_accuracy: 0.8800 - val_loss: 0.3324\n",
      "Epoch 23/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 470ms/step - accuracy: 0.8853 - loss: 0.2838 - val_accuracy: 0.8200 - val_loss: 0.3511\n",
      "Epoch 24/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 488ms/step - accuracy: 0.8881 - loss: 0.2678 - val_accuracy: 0.8600 - val_loss: 0.3255\n",
      "Epoch 25/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 485ms/step - accuracy: 0.8857 - loss: 0.2607 - val_accuracy: 0.8700 - val_loss: 0.3085\n",
      "Epoch 26/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 478ms/step - accuracy: 0.9108 - loss: 0.2336 - val_accuracy: 0.8700 - val_loss: 0.2909\n",
      "Epoch 27/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 520ms/step - accuracy: 0.9085 - loss: 0.2305 - val_accuracy: 0.8800 - val_loss: 0.2908\n",
      "Epoch 28/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 480ms/step - accuracy: 0.9051 - loss: 0.2307 - val_accuracy: 0.8700 - val_loss: 0.3017\n",
      "Epoch 29/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 479ms/step - accuracy: 0.9286 - loss: 0.1867 - val_accuracy: 0.9000 - val_loss: 0.2523\n",
      "Epoch 30/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 474ms/step - accuracy: 0.9242 - loss: 0.1861 - val_accuracy: 0.9000 - val_loss: 0.2382\n",
      "Epoch 31/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 495ms/step - accuracy: 0.9020 - loss: 0.2011 - val_accuracy: 0.8900 - val_loss: 0.2754\n",
      "Epoch 32/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 472ms/step - accuracy: 0.9338 - loss: 0.1680 - val_accuracy: 0.9400 - val_loss: 0.2146\n",
      "Epoch 33/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 470ms/step - accuracy: 0.9355 - loss: 0.1573 - val_accuracy: 0.9300 - val_loss: 0.1991\n",
      "Epoch 34/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 465ms/step - accuracy: 0.9397 - loss: 0.1546 - val_accuracy: 0.9200 - val_loss: 0.2163\n",
      "Epoch 35/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 460ms/step - accuracy: 0.9393 - loss: 0.1505 - val_accuracy: 0.9100 - val_loss: 0.2127\n",
      "Epoch 36/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 470ms/step - accuracy: 0.9482 - loss: 0.1520 - val_accuracy: 0.9200 - val_loss: 0.2290\n",
      "Epoch 37/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 472ms/step - accuracy: 0.9259 - loss: 0.1730 - val_accuracy: 0.9400 - val_loss: 0.1945\n",
      "Epoch 38/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 479ms/step - accuracy: 0.9525 - loss: 0.1357 - val_accuracy: 0.9100 - val_loss: 0.2275\n",
      "Epoch 39/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 474ms/step - accuracy: 0.9613 - loss: 0.1157 - val_accuracy: 0.9300 - val_loss: 0.1857\n",
      "Epoch 40/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 497ms/step - accuracy: 0.9593 - loss: 0.1183 - val_accuracy: 0.9500 - val_loss: 0.1795\n"
     ]
    }
   ],
   "source": [
    "models_info = models.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=1800 // 64,\n",
    "    epochs=40,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=1800 // 64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.save_weights('model/model_weights.weights.h5')\n",
    "model_json = models.to_json()\n",
    "with open(\"model/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "with open('model/history.pckl', 'wb') as f:\n",
    "    pickle.dump(models_info.history, f)\n",
    "with open('model/history.pckl', 'rb') as f:\n",
    "    data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model Accuracy = 95.70164084434509\n"
     ]
    }
   ],
   "source": [
    "acc = data['accuracy']\n",
    "accuracy = acc[-1] * 100\n",
    "print(\"Training Model Accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
